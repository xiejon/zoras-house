{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to load the model in  word2vec_model.txt ...\n",
      "Model loaded.\n",
      "\n",
      "The model built is KeyedVectors<vector_size=300, 43981 keys> \n",
      "\n",
      "The vocabulary has 43981 words\n",
      "Each word is a vector of size 300\n",
      "\n",
      "Try m.get_vector('python') to see a the vector for 'python'!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "def read_word2vec_model(filename):  \n",
    "    try:\n",
    "        print(\"Starting to load the model in \", filename, \"...\")\n",
    "        model = KeyedVectors.load_word2vec_format(filename, binary=False)\n",
    "        print(\"Model loaded.\\n\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"  [WARNING]    The file {filename} was not found.     [WARNING]  \")\n",
    "        return None   # returning a placeholder, not a model\n",
    "\n",
    "    # let's print some attributes\n",
    "    print(\"The model built is\", model, \"\\n\")\n",
    "    print(\"The vocabulary has\", model.vectors.shape[0], \"words\")   # The vocabulary has 43981 words\n",
    "    print(\"Each word is a vector of size\", model.vector_size)  # 300\n",
    "    print(\"\\nTry m.get_vector('python') to see a the vector for 'python'!\\n\")\n",
    "    model.fill_norms()  # freezes the model, m, as-is (no more training)\n",
    "    # we weren't going to train more, so no worries (in week7, at least)\n",
    "    return model\n",
    "\n",
    "\n",
    "m = read_word2vec_model(filename = \"word2vec_model.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(word1, word2):\n",
    "    try:\n",
    "        return float(m.similarity(word1, word2))\n",
    "    except Exception:\n",
    "        print(\"Invalid Choice(s)\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity('mother', 'mom')\n",
    "# similarity('entrepreneur', 'business')\n",
    "# similarity('single', 'married')\n",
    "# similarity('drink', 'alcohol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snake\n"
     ]
    }
   ],
   "source": [
    "initial_words = \"snake serpent code ai ml programming\".split()\n",
    "key = 'python'\n",
    "\n",
    "def mostSimilar(initial_words = initial_words, key=key):\n",
    "    LoS = []\n",
    "    LoW = []\n",
    "    maxMatch = [\"\", 0]\n",
    "    for w in initial_words:\n",
    "        if w in m:  # is the word, w present in the vocabulary?\n",
    "            similarity = m.similarity(key,w)\n",
    "\n",
    "            if similarity > maxMatch[1]:\n",
    "                maxMatch[0] = w\n",
    "                maxMatch[1] = round(float(similarity), 2)\n",
    "                \n",
    "            # print(f\"similarity between {key} and {w}: {similarity:1.2f}\", )\n",
    "            LoS.append( similarity )\n",
    "            LoW.append( w )\n",
    "        else:\n",
    "            pass\n",
    "            #print(f\"  __  {w}  __ was not in the vocabulary\", )   # not every word will be present\n",
    "\n",
    "    # print(f\"LoS is {LoS}\")\n",
    "    # print(f\"LoW is {LoW}\")\n",
    "    print(maxMatch[0])\n",
    "\n",
    "mostSimilar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
